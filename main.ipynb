{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [DCC 030] Aprendizado Profundo para Processamento de Linguagem Natural: Trabalho Prático 2\n",
    "__Aluno:__\n",
    "- Eduardo Villani de Carvalho Filho - 2015104008\n",
    "---\n",
    "# [Parte 1] O trabalho"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bibliotecas que serão utilizadas\n",
    "\n",
    "Aqui é definido todas as bibliotecas que serão utilizadas ao longo deste trabalho."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import nltk\n",
    "import ssl\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tqdm\n",
    "\n",
    "from typing import Union\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Eventual problema de SSL\n",
    "\n",
    "Há um pequeno problema no sistema de download da biblioteca utilizada, por isso devemos rodar a\n",
    "linha abaixo para configurar o certificado ssl do computador."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introdução\n",
    "\n",
    "Este trabalho tem como objetivo pôr em prática o que foi visto em sala de aula do conceito de\n",
    "POS Tagging. O POS Tagging tem por objetivo classificar as palavras em classes gramaticais, isto\n",
    "é, pegando uma frase genérica como: \"Eu lavei meu carro ontem\", o POS Tagging teria por objetivo\n",
    "saber classificar \"Eu\" como um Pronome Pessoa, \"lavei\" como um verbo, \"meu\" como um pronome\n",
    "possessivo, \"carro\" como um substantivo e \"ontem\" como um advérbio de tempo, além de outras\n",
    "classificações possíveis, como \"meu carro ontem\" como um objeto direto.\n",
    "\n",
    "Para a elaboração deste trabalhos, iremos utilizar o corpus Mac Morpho (colocar link aqui),\n",
    "o qual contém classificação de sentenças em português brasileiro feita pela USP. Pegando um exemplo prático\n",
    "utilizando a biblioteca do Python NLTK:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package mac_morpho to\n",
      "[nltk_data]     /Users/eduardovillani/nltk_data...\n",
      "[nltk_data]   Package mac_morpho is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51397\n",
      "('Jersei', 'N')\n",
      "('atinge', 'V')\n",
      "('média', 'N')\n",
      "('de', 'PREP')\n",
      "('Cr$', 'CUR')\n",
      "('1,4', 'NUM')\n",
      "('milhão', 'N')\n",
      "('em', 'PREP|+')\n",
      "('a', 'ART')\n",
      "('venda', 'N')\n",
      "('de', 'PREP|+')\n",
      "('a', 'ART')\n",
      "('Pinhal', 'NPROP')\n",
      "('em', 'PREP')\n",
      "('São', 'NPROP')\n",
      "('Paulo', 'NPROP')\n"
     ]
    }
   ],
   "source": [
    "nltk.download('mac_morpho')\n",
    "mac_morpho = nltk.corpus.mac_morpho\n",
    "print(len(mac_morpho.tagged_sents()))\n",
    "for word_tagged in mac_morpho.tagged_sents()[0]:\n",
    "    print(word_tagged)\n",
    "\n",
    "del word_tagged"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como podemos notar, o nltk apresenta a classificação de cada palavra e ainda a junção de dois tipos\n",
    "diferentes para formar um só, como de + a formando da, como uma preposição e um artigo.\n",
    "\n",
    "Ao longo deste trabalho, iremos ver o funcionamento do NLTK (para se familiarizar com a biblioteca e o POS Tagging),\n",
    "passando por uma avaliação dos classificadores do NLTK e finalizando momontando um modelo usando XYZ\n",
    "para comparação com estes classificadores."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [Parte 2] Conhecendo o nltk e o MacMorphus\n",
    "\n",
    "bla bla bla"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def most_commom_tags(corpus, n):\n",
    "    def simplify_tag(t):\n",
    "        \"\"\"Retirado de: http://www.nltk.org/howto/portuguese_en.html\"\"\"\n",
    "        if \"+\" in t:\n",
    "            return t[t.index(\"+\")+1:]\n",
    "        else:\n",
    "            return t\n",
    "\n",
    "    tags = [simplify_tag(tag) for (word,tag) in corpus.tagged_words()]\n",
    "    fd_tags =  nltk.FreqDist(tags)\n",
    "    for tag in list(fd_tags.keys())[:n]:\n",
    "        print(tag)\n",
    "    del fd_tags\n",
    "    del tags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 10\n",
    "print(f\"As {n} tags mais comuns em pt-BR:\")\n",
    "most_commom_tags(mac_morpho, n)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(mac_morpho.tagged_words())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 10\n",
    "print(f\"As {n} palavras mais comuns em pt-BR:\\n{fd.most_common(n)}\")\n",
    "del fd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [PARTE 3] Testando modelos de determinação de Tags com o nltk\n",
    "\n",
    "ESCREVER ALGO AQUI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dados de Treino e Dados de Teste\n",
    "\n",
    "Vamos usar 80% dos dados para testes e 20% para treino."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "k = 0.8\n",
    "data = mac_morpho.tagged_sents()\n",
    "tot = len(data)\n",
    "tot_train_samples = int(np.ceil(tot*k))\n",
    "\n",
    "train_data = data[:tot_train_samples]\n",
    "test_data = data[tot_train_samples:]\n",
    "\n",
    "del data, k, tot, tot_train_samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fábricas de Modelos\n",
    "\n",
    "Para facilitar o desenvolvimento do trabalho, será feito uma fábrica de modelos para criação e gerenciamento dos mesmos.\n",
    "Abaixo explicamos a função de cada classe criada."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tipos de Modelos\n",
    "\n",
    "Aqui definimos os tipos de modelos que serão usados para avaliar a acurácia."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "class ModelType:\n",
    "    TAGGER = 'TAGGER'\n",
    "    AFFIX2 = 'AFFIX2'\n",
    "    AFFIX3= 'AFFIX3'\n",
    "    AFFIX4 = 'AFFIX4'\n",
    "    AFFIX5 = 'AFFIX5'\n",
    "    AFFIX6 = 'AFFIX6'\n",
    "    UNIGRAM = 'UNIGRAM'\n",
    "    BIGRAM = 'BIGRAM'\n",
    "    TRIGRAM = 'TRIGRAM'\n",
    "    BRILL_TAGGER = 'BRILL_TAGGER'\n",
    "    NAIVES_BAYES = 'NAIVES_BAYES'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tagger de Modelos\n",
    "\n",
    "Uma classe básica que contém informações dos modelos (valor padrão no texto, modelos, classificador usado,\n",
    "acurácia e se a acurácia está em porcentual ou em valores unitário). Foi feito uma subclasse para\n",
    "controle dos modelos."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "class Tagger:\n",
    "    class ModelDict:\n",
    "        def __init__(self, name: str, classifier):\n",
    "            self._data = {\n",
    "                'name': name,\n",
    "                'accuracy': None,\n",
    "                'accuracy_type': \"unit\",\n",
    "                'model': None,\n",
    "                'classifier': classifier\n",
    "            }\n",
    "\n",
    "        @property\n",
    "        def name(self) -> str:\n",
    "            return self['name']\n",
    "\n",
    "        @property\n",
    "        def accuracy(self) -> Union[float, None]:\n",
    "            return self['accuracy']\n",
    "\n",
    "        @property\n",
    "        def model(self):\n",
    "            return self['model']\n",
    "\n",
    "        @property\n",
    "        def classifier(self):\n",
    "            return self['classifier']\n",
    "\n",
    "        def __str__(self):\n",
    "            return str(self._data)\n",
    "\n",
    "        def __getitem__(self, item: str):\n",
    "            return self._data[item]\n",
    "\n",
    "        def __setitem__(self, item: str, value):\n",
    "            self._data[item] = value\n",
    "\n",
    "        __repr__ = __str__\n",
    "\n",
    "    def __init__(self, value: str):\n",
    "        self._data = {\n",
    "            \"value\": value,\n",
    "            'models': {\n",
    "                ModelType.TAGGER: Tagger.ModelDict(ModelType.TAGGER, nltk.DefaultTagger),\n",
    "                ModelType.AFFIX2: Tagger.ModelDict(ModelType.AFFIX2, nltk.AffixTagger),\n",
    "                ModelType.AFFIX3: Tagger.ModelDict(ModelType.AFFIX3, nltk.AffixTagger),\n",
    "                ModelType.AFFIX4: Tagger.ModelDict(ModelType.AFFIX4, nltk.AffixTagger),\n",
    "                ModelType.AFFIX5: Tagger.ModelDict(ModelType.AFFIX5, nltk.AffixTagger),\n",
    "                ModelType.AFFIX6: Tagger.ModelDict(ModelType.AFFIX6, nltk.AffixTagger),\n",
    "                ModelType.UNIGRAM: Tagger.ModelDict(ModelType.UNIGRAM, nltk.UnigramTagger),\n",
    "                ModelType.BIGRAM: Tagger.ModelDict(ModelType.BIGRAM, nltk.BigramTagger),\n",
    "                ModelType.TRIGRAM: Tagger.ModelDict(ModelType.TRIGRAM, nltk.TrigramTagger),\n",
    "                ModelType.BRILL_TAGGER: Tagger.ModelDict(ModelType.BRILL_TAGGER, nltk.BrillTaggerTrainer),\n",
    "                ModelType.NAIVES_BAYES: Tagger.ModelDict(ModelType.NAIVES_BAYES, nltk.ClassifierBasedPOSTagger)\n",
    "    }\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def value(self) -> str:\n",
    "        return self['value']\n",
    "\n",
    "    @property\n",
    "    def models(self)->dict:\n",
    "        return self['models']\n",
    "\n",
    "\n",
    "    def evaluate_models(self, test_data, name):\n",
    "        with tqdm.notebook.tqdm(self.models, position=1, desc=f'Evaluating models for {name}') as inner_for:\n",
    "            for m in inner_for:\n",
    "                model = self.models[m]\n",
    "                accuracy_model = model.accuracy\n",
    "                if accuracy_model is not None and isinstance(accuracy_model, float):\n",
    "                    pass\n",
    "                m_model = model.evaluate(test_data)\n",
    "                self['models'][m]['accuracy'] = m_model\n",
    "\n",
    "\n",
    "    def generate_models(self, train_data, name):\n",
    "        with tqdm.notebook.tqdm(self.models, position=1, desc=f'Generating models for {name}') as inner_for:\n",
    "            for m in inner_for:\n",
    "                current_model = self['models'][m]['model']\n",
    "                pathlib.Path(\"models\").mkdir(parents=True, exist_ok=True)\n",
    "                file_name = f\"POS_tagger_{self['value']}_{self['models'][m]['name']}\"\n",
    "                file_path = f\"models/{file_name}.pkl\"\n",
    "                tagger = None\n",
    "                if current_model is None:\n",
    "                    try:\n",
    "                        self['models'][m]['model'] = joblib.load(file_path)\n",
    "                    except FileNotFoundError:\n",
    "                        if m == ModelType.TAGGER:\n",
    "                            tagger = self['models'][m]['classifier'](self['value'])\n",
    "                        elif m == ModelType.NAIVES_BAYES:\n",
    "                            tagger = self['models'][m]['classifier'](train=train_data)\n",
    "                        elif m == ModelType.BRILL_TAGGER:\n",
    "                            backoff = self['models'][ModelType.TRIGRAM]['model']\n",
    "                            tagger = self['models'][m]['classifier'](backoff, nltk.brill.fntbl37(), trace=True)\n",
    "                            tagger = tagger.train(train_data)\n",
    "                        elif m == ModelType.AFFIX2:\n",
    "                            backoff = self['models'][ModelType.TAGGER]['model']\n",
    "                            tagger = self['models'][m]['classifier'](train_data,affix_length=-2, backoff=backoff)\n",
    "                        elif m == ModelType.AFFIX3:\n",
    "                            backoff = self['models'][ModelType.AFFIX2]['model']\n",
    "                            tagger = self['models'][m]['classifier'](train_data,affix_length=-3, backoff=backoff)\n",
    "                        elif m == ModelType.AFFIX4:\n",
    "                            backoff = self['models'][ModelType.AFFIX3]['model']\n",
    "                            tagger = self['models'][m]['classifier'](train_data,affix_length=-4, backoff=backoff)\n",
    "                        elif m == ModelType.AFFIX5:\n",
    "                            backoff = self['models'][ModelType.AFFIX4]['model']\n",
    "                            tagger = self['models'][m]['classifier'](train_data,affix_length=-5, backoff=backoff)\n",
    "                        elif m == ModelType.AFFIX6:\n",
    "                            backoff = self['models'][ModelType.AFFIX5]['model']\n",
    "                            tagger = self['models'][m]['classifier'](train_data,affix_length=-6, backoff=backoff)\n",
    "                        elif m == ModelType.UNIGRAM:\n",
    "                            backoff = self['models'][ModelType.AFFIX6]['model']\n",
    "                            tagger = self['models'][m]['classifier'](train_data, backoff=backoff)\n",
    "                        elif m == ModelType.BIGRAM:\n",
    "                            backoff = self['models'][ModelType.UNIGRAM]['model']\n",
    "                            tagger = self['models'][m]['classifier'](train_data, backoff=backoff)\n",
    "                        elif m == ModelType.TRIGRAM:\n",
    "                            backoff = self['models'][ModelType.BIGRAM]['model']\n",
    "                            tagger = self['models'][m]['classifier'](train_data, backoff=backoff)\n",
    "                        if tagger is not None:\n",
    "                            self['models'][m]['model'] = tagger\n",
    "                            joblib.dump(tagger, file_path)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self._data[item]\n",
    "\n",
    "    def __setitem__(self, item, value):\n",
    "        self._data[item] = value\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self._data)\n",
    "\n",
    "    __repr__ = __str__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dícionarios de Tags\n",
    "\n",
    "Classe que contém todas as tags utilizadas e com possibilidade de gerar todas (somente algumas), além de avaliá-lo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "class TagsDict:\n",
    "    def __init__(self, train_data, test_data):\n",
    "        self._train_data = train_data\n",
    "        self._test_data = test_data\n",
    "        self._data = {\n",
    "            \"ADJETIVO\": Tagger(\"ADJ\"),\n",
    "            \"ADVÉRBIO\": Tagger(\"ADV\"),\n",
    "            \"ADVÉRBIO CONECTIVO SUBORDINATIVO\": Tagger(\"ADV-KS\"),\n",
    "            \"ADVÉRBIO RELATIVO SUBORDINATIVO\": Tagger(\"ADV-KS-REL\"),\n",
    "            \"ARTIGO\": Tagger(\"ART\"),\n",
    "            \"CONJUNÇÃO COORDENATIVA\": Tagger(\"KC\"),\n",
    "            \"CONJUNÇÃO SUBORDINATIVA\": Tagger(\"KS\"),\n",
    "            \"INTERJEIÇÃO\": Tagger(\"IN\"),\n",
    "            \"NOME\": Tagger(\"N\"),\n",
    "            \"NOME PRÓPRIO\": Tagger(\"NPROP\"),\n",
    "            \"NUMERAL\": Tagger(\"NUM\"),\n",
    "            \"PARTICÍPIO\": Tagger(\"PCP\"),\n",
    "            \"PALAVRA DENOTATIVA\": Tagger(\"PDEN\"),\n",
    "            \"PREPOSIÇÃO\": Tagger(\"PREP\"),\n",
    "            \"PRONOME ADJETIVO\": Tagger(\"PROADJ\"),\n",
    "            \"PRONOME CONECTIVO SUBORDINATIVO\": Tagger(\"PRO-KS\"),\n",
    "            \"PRONOME PESSOAL\": Tagger(\"PROPESS\"),\n",
    "            \"PRONOME RELATIVO CONECTIVO SUBORDINATIVO\": Tagger(\"PRO-KS-REL\"),\n",
    "            \"PRONOME SUBSTANTIVO\": Tagger(\"PROSUB\"),\n",
    "            \"VERBO\": Tagger(\"V\"),\n",
    "            \"VERBO AUXILIAR\": Tagger(\"VAUX\"),\n",
    "            \"SÍMBOLO DE MOEDA CORRENTE\": Tagger(\"CUR\")\n",
    "        }\n",
    "\n",
    "    def train_all_models(self):\n",
    "        with tqdm.notebook.tqdm(self._data, position=0, desc=\"Model Generating...\") as main_for:\n",
    "            for t in main_for:\n",
    "                self._data[t].generate_models(self._train_data, t)\n",
    "\n",
    "    def evaluate_all_models(self):\n",
    "        with tqdm.notebook.tqdm(self._data, position=0, desc=\"Model Evaluating...\") as main_for:\n",
    "            for t in main_for:\n",
    "                self._data[t].evaluate_models(self._test_data, t)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self._data)\n",
    "    __repr__ = __str__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conhecendo os classificadores do NLTK\n",
    "\n",
    "Aqui faremos uma breve explicação de como cada classificador do NLTK funciona para melhor entendimento."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Default Tagger\n",
    "\n",
    "Primeiramente iremos utilizar o Default Tagger do nltk para classificar o texto aleatoriamente em alguma\n",
    "classe gramatical. Ela servirá como um valor base para demais métodos que serão usados. Como padrão, iremos\n",
    "usar a tag N, de nome. A escolha é puramente por ser a tag mais comum, mas qualquer outra tag poderia\n",
    "ser usada.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Affix\n",
    "\n",
    "O AffixTagger se baseia em sufixos e prefixos. A língua portuguesa tem uma forma relação\n",
    "entre os sufixos das palavras e sua classe. À exemplo: palavras terminar em -er, -ir ou -ar são em\n",
    "sua maioria verbos. Palavras terminadas em -mente são advérbios de modo. O limite colocado foi 6,\n",
    "justamente pois -mente é o maior sufixo existente em portugues, portando de 5 para 6 não haverá grandes\n",
    "diferenças. Os prefixos foram ignorados por não apresentarem muita relação."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Unigram\n",
    "O UnigramTagger considera cada palavra de uma vez e determina o contexto da palavra."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bigram\n",
    "O BigramTagger funciona como o Unigram, mas considera o conjunto de duas palavras: \"Eu amo batata\", os bigramas\n",
    "são \"eu amo\" e \"amo batata\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trigram\n",
    "O TrigramTagger segue a mesma lógica do Unigram e do Trigram.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Brill Tagger\n",
    "O Brill Tagger é um tipo de classificador de aprendizado supervisionado que tenta determinar regras\n",
    "para ajudar na classificação, i.e, o erro é minimizado na classificação seguida de associar uma tag a uma regra\n",
    "gerada pelo algoritmo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gerando os modelos\n",
    "\n",
    "Aqui iremos gerar todos os modelos para futura avaliação."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "Model Generating...:   0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1c9f67c659241189bf0adecee56d5a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating models for ADJETIVO:   0%|          | 0/11 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89ece2910cb24c1d9461a80b258a1661"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating models for ADVÉRBIO:   0%|          | 0/11 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0f0dfa49d204e96a95d4c041d88bab7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBL train (fast) (seqs: 41118; tokens: 913108; tpls: 37; min score: 2; min acc: None)\n",
      "Finding initial useful rules...\n",
      "    Found 848255 useful rules.\n",
      "Selecting rules...\n",
      "TBL train (fast) (seqs: 41118; tokens: 913108; tpls: 37; min score: 2; min acc: None)\n",
      "Finding initial useful rules...\n",
      "    Found 848255 useful rules.\n",
      "Selecting rules...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Generating models for ADVÉRBIO CONECTIVO SUBORDINATIVO:   0%|          | 0/11 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e00def6b82140a1b1064ddf9af538e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_dict = TagsDict(test_data=test_data, train_data=train_data)\n",
    "tags_dict.train_all_models()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Acuracias\n",
    "\n",
    "Aqui iremos avaliar a acurácias de todos os modelos por meio do métodos .evalute() de todos os classificadores\n",
    "do nltk. Em seguida, iremos compará-los.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tags_dict.evaluate_all_models()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}